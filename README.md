Per eseguire i test case 1 e 2:
1) eseguire lo script utilities/GenerateDataset.py compilando il file utilities/data-for-GenerateDataset.txt:

alpha: ...
nome_file: ...
K: ...
K_val: ...
K_test: ...
S0: ...
beta0_inf: ...
beta0_sup: ...
N: ...
S_inf: ...
t_max: ...
n_variabili: ...

dove:
* 'alpha' è il parametro del SIR
* in 'nome_file' bisogna inserire il nome del file in cui sarà salvato il dataset
* 'K', 'K_val', 'K_test' indicano rispettivamente la dimensione del train set, validation set e test set
* 'S0' è il valore iniziale dei Suscettibili (che verrà utilizzato per calcolare beta_ref)
* 'S_inf' è il valore a regime dei Suscettibili (che verrà utilizzato per calcolare beta_ref)
* 'beta0_inf', 'beta0_sup' sono gli estremi in cui vengono generati casualmente i valori iniziali del parametro beta
* 'N' è il numero di timesteps
* 't_max' l'orizzonte temporale della simulazione
* 'n_variabili' è il numero delle variabili di interesse: se mpostato su 1 vengono generate temperature casuali, 
  mentre se impostato su 2 oltre alle temperature vengono generati anche i livelli di isolamento

2) compilare il file data.txt con i seguenti campi:

training_steps: ...
S0: ...
I0: ...
S_inf: ...
alpha: ...
n_hidden: ...
dataset: ...
learning_rate: ...
display_step: ...
t_max: ...
tau: ...
num_layers: ...

dove: 
* 'S0', 'S_inf', 'alpha', 't_max' come prima
* 'training_steps' è il numero di iterazioni del training
* 'n_hidden' è il numero di neuroni che compongono gli hidden layer della rete
* 'num_layers' è il numero di layers della rete (è possibile scegliere tra 1 e 2)
* 'tau' è il parametro dell'equazione di beta (fare riferimento al report)
* 'dataset' è il nome del file da cui caricare il dataset
* 'I0' è il numero iniziale di infetti
* 'display_step' indica ogni quante iterazioni viene stampta la loss sul training set e validation set

3) eseguire lo script Main.py con il comando:
	python3 Main.py --test-case
Per il training si possono utilizzare le possibili opzioni:

--load-model nome_rete : viene caricata la rete 'nome_rete' (quindi non ne viene creata una nuova)
--train : viene eseguito il training della rete
--plot-train : vengono mostrati alla fine del training i plot del training set
--plot-test : vengono mostrati alla fine del training i plot del test set
--save-model nome_rete : viene salvato il modello come 'nome_rete'


Per eseguire i training utilizzando il modello basato sui beta-log (bisogna avere clonata la repository del DPC :https://github.com/pcm-dpc/COVID-19.git):
1) eseguire lo script GenerateDataset_BetaLog.py dentro cui modificare le variabili:

n_timesteps = ...
path_i = ...
regione_beta = ...
K = ...
n_giorni = ...
overlap = ...
path_t = ...
regione_temp = ...
nome_file = ...
use_zone = ...

dove:
* 'path_i' è il percorso del file contenente le osservazioni sugli infetti (cartella 'dati-regioni' della repository del DPC)
* 'path_t' è il percorso del file contenente le osservazioni sulle temperature ('.\Temperature')
* 'regione_beta': una list contenente le regioni di interesse da cui estrarre gli infetti (e.g.: regione_beta = ['Lombardia'])
* 'regione_temp': una list contenente le città di interesse da cui estrarre le temperature (e.g.: regione_temp = ['Milano'])
* 'K' la dimensione del training set
* 'n_giorni' è il numero di giorni che verrà utilizzato per costruire gli intervalli del dataset
* 'overlap' è il numero di giorni di overlap tra gli intervalli
* 'n_timesteps' è il numero di timesteps di ogni intervallo nel dataset
* 'nome_file' è il nome con cui verrà salvato il dataset
* 'use_zone' se impostato su True estrarrà anche i livelli di isolamento da usare nel training

2) compilare il file data.txt come spiegato per i test case (anche se alcuni dati non verranno utlizzati)

3) eseguire lo script Main.py con il comando:
	python3 Main.py --beta-log

Per il training si possono utilizzare le opzioni già spiegate per i test case 1 e 2.
